## Read3:
# ----------------

#### What is Big O Notation?
##### Big O notation is one of the most fundamental tools for computer scientists to analyze the cost of an algorithm. It is a good practice for software engineers to understand in-depth as well.

# ----------------

#### Why Do we use Big O Notation?
##### Big O notation is used in Computer Science to describe the performance or complexity of an algorithm. Big O specifically describes the worst-case scenario, and can be used to describe the execution time required or the space used (e.g. in memory or on disk) by an algorithm.

# ---------------

#### Examples of orders of big O notation?
##### O(1), O(n), O(N²), O(2^N) and Logarithms

# ---------------

#### Describe O(1) order?
##### O(1) describes an algorithm that will always execute in the same time (or space) regardless of the size of the input data set

# --------------

#### What do O(N²) represents?
##### O(N²) represents an algorithm whose performance is directly proportional to the square of the size of the input data set.

# --------------

## Resources

[Link1](https://www.freecodecamp.org/news/big-o-notation-why-it-matters-and-why-it-doesnt-1674cfa8a23c/)
